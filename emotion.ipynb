{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31331ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>prompt</th>\n",
       "      <th>utterance</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>1</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>I remember going to see the fireworks with my ...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>2</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>Was this a friend you were in love with_comma_...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>3</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>This was a best friend. I miss her.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>4</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>Where has she gone?</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:0_conv:1</td>\n",
       "      <td>5</td>\n",
       "      <td>I remember going to the fireworks with my best...</td>\n",
       "      <td>We no longer talk.</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        conv_id  utterance_idx  \\\n",
       "0  hit:0_conv:1              1   \n",
       "1  hit:0_conv:1              2   \n",
       "2  hit:0_conv:1              3   \n",
       "3  hit:0_conv:1              4   \n",
       "4  hit:0_conv:1              5   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  I remember going to the fireworks with my best...   \n",
       "1  I remember going to the fireworks with my best...   \n",
       "2  I remember going to the fireworks with my best...   \n",
       "3  I remember going to the fireworks with my best...   \n",
       "4  I remember going to the fireworks with my best...   \n",
       "\n",
       "                                           utterance  label  \n",
       "0  I remember going to see the fireworks with my ...     13  \n",
       "1  Was this a friend you were in love with_comma_...     13  \n",
       "2                This was a best friend. I miss her.     13  \n",
       "3                                Where has she gone?     13  \n",
       "4                                 We no longer talk.     13  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 讀取資料集\n",
    "train = pd.read_csv(\"train/fixed_train.csv\")#.sample(n=5000)\n",
    "valid = pd.read_csv(\"train/fixed_valid.csv\")#.sample(n=1000)\n",
    "test = pd.read_csv(\"train/fixed_test.csv\")#.sample(n=1000)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db047cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning about _comma_\n",
    "train['prompt'] = train['prompt'].map(lambda x:x.replace('_comma_',','))\n",
    "train['utterance'] = train['utterance'].map(lambda x:x.replace('_comma_',','))\n",
    "valid['prompt'] = valid['prompt'].map(lambda x:x.replace('_comma_',','))\n",
    "valid['utterance'] = valid['utterance'].map(lambda x:x.replace('_comma_',','))\n",
    "test['prompt'] = test['prompt'].map(lambda x:x.replace('_comma_',','))\n",
    "test['utterance'] = test['utterance'].map(lambda x:x.replace('_comma_',','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80494907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練樣本數： 84169\n",
      "驗證樣本數： 12078\n",
      "測試樣本數： 10973\n"
     ]
    }
   ],
   "source": [
    "print(\"訓練樣本數：\", len(train))\n",
    "print(\"驗證樣本數：\", len(valid))\n",
    "print(\"測試樣本數：\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13c2031a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_label = {'sad': 0, 'trusting': 1, 'terrified': 2, 'caring': 3, 'disappointed': 4,\n",
    "         'faithful': 5, 'joyful': 6, 'jealous': 7, 'disgusted': 8, 'surprised': 9,\n",
    "         'ashamed': 10, 'afraid': 11, 'impressed': 12, 'sentimental': 13, \n",
    "         'devastated': 14, 'excited': 15, 'anticipating': 16, 'annoyed': 17, 'anxious': 18,\n",
    "         'furious': 19, 'content': 20, 'lonely': 21, 'angry': 22, 'confident': 23,\n",
    "         'apprehensive': 24, 'guilty': 25, 'embarrassed': 26, 'grateful': 27,\n",
    "         'hopeful': 28, 'proud': 29, 'prepared': 30, 'nostalgic': 31}\n",
    "len(emotion_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e4d5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.utils.data import Dataset\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# 取得此預訓練模型所使用的 tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "class EmotionDataset(Dataset):\n",
    "    # 讀取前處理後的 tsv 檔並初始化一些參數\n",
    "    def __init__(self, mode, df, tokenizer):\n",
    "        assert mode in [\"train\", \"valid\", \"test\"]\n",
    "        self.mode = mode\n",
    "        self.df = df.fillna(\"\")\n",
    "        self.len = len(self.df)\n",
    "        self.label_map = emotion_label\n",
    "#         {'sad': 0, 'trusting': 1, 'terrified': 2, 'caring': 3, 'disappointed': 4,\n",
    "#          'faithful': 5, 'joyful': 6, 'jealous': 7, 'disgusted': 8, 'surprised': 9,\n",
    "#          'ashamed': 10, 'afraid': 11, 'impressed': 12, 'sentimental': 13, \n",
    "#          'devastated': 14, 'excited': 15, 'anticipating': 16, 'annoyed': 17, 'anxious': 18,\n",
    "#          'furious': 19, 'content': 20, 'lonely': 21, 'angry': 22, 'confident': 23,\n",
    "#          'apprehensive': 24, 'guilty': 25, 'embarrassed': 26, 'grateful': 27,\n",
    "#          'hopeful': 28, 'proud': 29, 'prepared': 30, 'nostalgic': 31}\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    # 這裡需要定義回傳一筆訓練 / 測試數據的函式，\n",
    "    # 也就是當以 [idx] 來 index Dataset 時，要回傳的東西\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == \"test\":\n",
    "            prompt, utterance = self.df.iloc[idx, 2:].values\n",
    "            label_tensor = None\n",
    "        else:\n",
    "            prompt, utterance, label = self.df.iloc[idx, 2:].values\n",
    "            label_tensor = torch.tensor(label)\n",
    "            \n",
    "        #text = '[CLS]' + prompt + ' [SEP]' + utterance + ' [SEP]'\n",
    "        text = '[CLS]' + utterance + ' [SEP]'\n",
    "#         tensor_arr = []\n",
    "#         i = 0\n",
    "#         for seg in utterance.split(\". \"):\n",
    "#             text = text + seg + ' [SEP]'\n",
    "#             tensor_arr.extend([i] * len(seg.split()))\n",
    "#             i+=1\n",
    "        word_pieces = tokenizer.tokenize(text)\n",
    "        \n",
    "        ids = self.tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "        tokens_tensor = torch.tensor(ids)\n",
    "        #segments_tensor = torch.tensor([0] * len(prompt) + [1] * len(utterance),dtype=torch.long)\n",
    "        segments_tensor = torch.tensor([0] * len(utterance.split()),dtype=torch.long)\n",
    "        return (tokens_tensor, segments_tensor, label_tensor)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "# 初始化 Dataset\n",
    "trainset = EmotionDataset(\"train\", train, tokenizer=tokenizer)\n",
    "validset = EmotionDataset(\"valid\", valid, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "508190d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[原始文本]\n",
      "句子 1：I remember going to the fireworks with my best friend. There was a lot of people, but it only felt like us in the world.\n",
      "句子 2：I remember going to see the fireworks with my best friend. It was the first time we ever spent time alone together. Although there was a lot of people, we felt like the only people in the world.\n",
      "分類  ：13\n",
      "\n",
      "--------------------\n",
      "\n",
      "[Dataset 回傳的 tensors]\n",
      "tokens_tensor  ：tensor([  101,  1045,  3342,  2183,  2000,  2156,  1996, 16080,  2007,  2026,\n",
      "         2190,  2767,  1012,  2009,  2001,  1996,  2034,  2051,  2057,  2412,\n",
      "         2985,  2051,  2894,  2362,  1012,  2348,  2045,  2001,  1037,  2843,\n",
      "         1997,  2111,  1010,  2057,  2371,  2066,  1996,  2069,  2111,  1999,\n",
      "         1996,  2088,  1012,   102])\n",
      "\n",
      "segments_tensor：tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "\n",
      "label_tensor   ：13\n",
      "\n",
      "--------------------\n",
      "\n",
      "[還原 tokens_tensors]\n",
      "[CLS] i remember going to see the fireworks with my best friend . it was the first time we ever spent time alone together . although there was a lot of people , we felt like the only people in the world . [SEP]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_idx = 0\n",
    "\n",
    "# 將原始文本拿出做比較\n",
    "prompt, utterance, label = trainset.df.iloc[sample_idx,2:].values\n",
    "\n",
    "# 利用剛剛建立的 Dataset 取出轉換後的 id tensors，\n",
    "# 經過我們自定義的 Dataset 後，trainset 現在已經是個 iterable 的 object，\n",
    "# 可以用編號來索引你想要去得的位置的 id tensors\n",
    "tokens_tensor, segments_tensor, label_tensor = trainset[sample_idx]\n",
    "\n",
    "# 將 tokens_tensor 還原成文本\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokens_tensor.tolist())\n",
    "combined_text = \" \".join(tokens)\n",
    "\n",
    "print(f\"\"\"[原始文本]\n",
    "句子 1：{prompt}\n",
    "句子 2：{utterance}\n",
    "分類  ：{label}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[Dataset 回傳的 tensors]\n",
    "tokens_tensor  ：{tokens_tensor}\n",
    "\n",
    "segments_tensor：{segments_tensor}\n",
    "\n",
    "label_tensor   ：{label_tensor}\n",
    "\n",
    "--------------------\n",
    "\n",
    "[還原 tokens_tensors]\n",
    "{combined_text}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad0c9c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# create_mini_batch 的參數 `samples` 是一個 list，裡頭的每個 element 都是\n",
    "# 剛剛定義的 `FakeNewsDataset` 回傳的一個樣本，每個樣本都包含 3 tensors：\n",
    "# - tokens_tensor\n",
    "# - segments_tensor\n",
    "# - label_tensor\n",
    "# 它會對前兩個 tensors 作 zero padding，並產生前面說明過的 masks_tensors\n",
    "def create_mini_batch(samples):\n",
    "    tokens_tensors = [s[0] for s in samples]\n",
    "    segments_tensors = [s[1] for s in samples]\n",
    "    \n",
    "    \n",
    "    # 測試集有 labels\n",
    "    if samples[0][2] is not None:\n",
    "        label_ids = torch.stack([s[2] for s in samples])\n",
    "    else:\n",
    "        label_ids = None\n",
    "    \n",
    "    # [TODO3]: 將 token_tensors 及 segments_tensors zero padding 到同樣長度，\n",
    "    # hint: 可以使用 import的 pad_sequence，記得 batch_first 要設為 True\n",
    "    #================================================\n",
    "    max_tok = 0\n",
    "    for i in range(1,len(tokens_tensors)):\n",
    "        if tokens_tensors[i].shape > tokens_tensors[max_tok].shape:\n",
    "            max_tok = i\n",
    "    temp = pad_sequence([segments_tensors[0],tokens_tensors[max_tok]],batch_first=True)\n",
    "    segments_tensors[0] = temp[0]\n",
    "    tokens_tensors = pad_sequence(tokens_tensors, \n",
    "                                  batch_first=True)\n",
    "    segments_tensors = pad_sequence(segments_tensors, \n",
    "                                    batch_first=True)\n",
    "    #================================================\n",
    "\n",
    "    masks_tensors = torch.zeros(tokens_tensors.shape,\n",
    "                                dtype=torch.long)\n",
    "    masks_tensors = masks_tensors.masked_fill(tokens_tensors != 0,1)\n",
    "    \n",
    "    return tokens_tensors, segments_tensors, masks_tensors, label_ids\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=128, \n",
    "                         collate_fn=create_mini_batch)\n",
    "\n",
    "validloader = DataLoader(validset, batch_size=256, \n",
    "                         collate_fn=create_mini_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c79c196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tokens_tensors.shape   = torch.Size([128, 49]) \n",
      "tensor([[ 101, 1045, 3342,  ...,    0,    0,    0],\n",
      "        [ 101, 2001, 2023,  ...,    0,    0,    0],\n",
      "        [ 101, 2023, 2001,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 101, 1037, 2095,  ...,    0,    0,    0],\n",
      "        [ 101, 2054, 2001,  ...,    0,    0,    0],\n",
      "        [ 101, 2009, 2001,  ...,    0,    0,    0]])\n",
      "------------------------\n",
      "segments_tensors.shape = torch.Size([128, 49])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "masks_tensors.shape    = torch.Size([128, 49])\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n",
      "------------------------\n",
      "label_ids.shape        = torch.Size([128])\n",
      "tensor([13, 13, 13, 13, 13, 13, 11, 11, 11, 11, 11, 11, 29, 29, 29, 29, 29,  5,\n",
      "         5,  5,  5,  2,  2,  2,  2,  2,  6,  6,  6,  6, 22, 22, 22, 22,  0,  0,\n",
      "         0,  0,  0,  7,  7,  7,  7,  2, 27, 27, 27, 27,  0,  0,  0,  0,  0, 30,\n",
      "        30, 30, 30, 26, 26, 26, 26, 22, 22, 22, 22, 22, 11, 11, 11, 11, 11, 11,\n",
      "        15, 15, 15, 15, 15, 17, 17, 17, 17, 22, 22, 22, 22, 21, 21, 21, 21, 29,\n",
      "        29, 29, 29, 29, 13, 13, 13, 13, 13, 13,  6,  6,  6,  6,  6, 10, 10, 10,\n",
      "        10, 10, 10, 10, 25, 25, 25, 25, 25,  9,  9,  9,  9, 31, 31, 31, 31, 23,\n",
      "        23, 23])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(trainloader))\n",
    "\n",
    "tokens_tensors, segments_tensors, \\\n",
    "    masks_tensors, label_ids = data\n",
    "\n",
    "print(f\"\"\"\n",
    "tokens_tensors.shape   = {tokens_tensors.shape} \n",
    "{tokens_tensors}\n",
    "------------------------\n",
    "segments_tensors.shape = {segments_tensors.shape}\n",
    "{segments_tensors}\n",
    "------------------------\n",
    "masks_tensors.shape    = {masks_tensors.shape}\n",
    "{masks_tensors}\n",
    "------------------------\n",
    "label_ids.shape        = {label_ids.shape}\n",
    "{label_ids}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2c82af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入一個預訓練好可以做多分類任務的模型，n_class = 32\n",
    "from transformers import BertForSequenceClassification\n",
    "from IPython.display import clear_output\n",
    "\n",
    "NUM_LABELS = 32\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=NUM_LABELS)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4f9e4f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda:0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b884d2f3efb4d3d939f0ea3b3eb02bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acc: 0.03710392187147287\n",
      "train loss: 0.027305214338408327\n",
      "CPU times: user 1min 32s, sys: 26.3 s, total: 1min 58s\n",
      "Wall time: 1min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm.notebook import tqdm\n",
    "def get_predictions(model, dataloader, compute_acc=False):\n",
    "    predictions = None\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            if next(model.parameters()).is_cuda:\n",
    "                data = [t.to(\"cuda:0\") for t in data if t is not None]\n",
    "                \n",
    "            if not compute_acc:\n",
    "                # 只是單純要回傳預測值的話，不用計算準確度也不用紀錄 loss\n",
    "                tokens_tensors, segments_tensors, masks_tensors = data[:3]\n",
    "                outputs = model(input_ids=tokens_tensors, \n",
    "                                token_type_ids=segments_tensors, \n",
    "                                attention_mask=masks_tensors)\n",
    "                logits = outputs[0]\n",
    "                _, pred = torch.max(logits.data, 1)\n",
    "            else:\n",
    "                # 否則就要計算 loss，這邊有一個小細節是 model 如果有吃 label 的話，\n",
    "                # output[0]會變成是 loss，沒有吃 label 時 output[0] 會是 logits\n",
    "                tokens_tensors, segments_tensors, masks_tensors, labels = data[:4]\n",
    "                outputs = model(input_ids=tokens_tensors, \n",
    "                                token_type_ids=segments_tensors, \n",
    "                                attention_mask=masks_tensors,\n",
    "                                labels=labels)\n",
    "                loss = outputs[0]\n",
    "                logits = outputs[1]\n",
    "                _, pred = torch.max(logits.data, 1)\n",
    "                running_loss += loss.item()\n",
    "                total += labels.size(0)\n",
    "                correct += (pred == labels).sum().item()\n",
    "                \n",
    "            if predictions is None:\n",
    "                predictions = pred\n",
    "            else:\n",
    "                predictions = torch.cat((predictions, pred))\n",
    "                \n",
    "    \n",
    "    if compute_acc:\n",
    "        acc = correct / total\n",
    "        loss = running_loss / total\n",
    "        return predictions, acc, loss\n",
    "    \n",
    "    return predictions\n",
    "    \n",
    "# 讓模型跑在 GPU 上並取得訓練集的分類準確率\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = 'cpu'\n",
    "# 這邊要記得確認 model 在 GPU 上運行 (投影片有說明)，否則會跑很久！\n",
    "print(\"device:\", device)\n",
    "model = model.to(device)\n",
    "_, train_acc, train_loss = get_predictions(model, trainloader, compute_acc=True)\n",
    "print(\"train acc:\", train_acc)\n",
    "print(\"train loss:\", train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98ff2d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6870173de7f241408c09b5746ea907cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11378668cb894d7797627a4a8485feca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d5b06422d248409645054c255e991b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] train loss: 0.021, train acc: 0.245, valid loss: 0.011, valid acc: 0.243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86334bed8a504eb797cb134e8a3c4b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31fab8d05c004a95b89540975199d666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57044f00114e480f85dfaf8e549fcd2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 2] train loss: 0.019, train acc: 0.294, valid loss: 0.010, valid acc: 0.278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a0a02052ad495dba566410f5cbb16d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22a75d67b664cb9856b9abc7accb79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/658 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f57e99122446437bbb2b7ef06ed78e34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 3] train loss: 0.018, train acc: 0.329, valid loss: 0.010, valid acc: 0.292\n",
      "CPU times: user 15min 20s, sys: 5min 18s, total: 20min 38s\n",
      "Wall time: 20min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "EPOCHS = 3  # 由於時間有限，訓練 3 輪看看表現如何就好\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for data in tqdm(trainloader):\n",
    "        \n",
    "        tokens_tensors, segments_tensors, \\\n",
    "        masks_tensors, labels = [t.to(device) for t in data]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(input_ids=tokens_tensors, \n",
    "                        token_type_ids=segments_tensors, \n",
    "                        attention_mask=masks_tensors, \n",
    "                        labels=labels)\n",
    "\n",
    "        loss = outputs[0]\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 紀錄當前 batch loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 計算分類準確率\n",
    "    _, train_acc, train_loss = get_predictions(model, trainloader, compute_acc=True)\n",
    "    _, valid_acc, valid_loss = get_predictions(model, validloader, compute_acc=True)\n",
    "    \n",
    "    print('[epoch %d] train loss: %.3f, train acc: %.3f, valid loss: %.3f, valid acc: %.3f' %\n",
    "          (epoch + 1, train_loss, train_acc, valid_loss, valid_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "315ec274",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'checkpoint.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9954f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", num_labels=NUM_LABELS)\n",
    "model.load_state_dict(torch.load(\"checkpoint.pt\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ca37a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>utterance_idx</th>\n",
       "      <th>prompt</th>\n",
       "      <th>utterance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>1</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>Yeah about 10 years ago I had a horrifying exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>2</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>Did you suffer any injuries?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>3</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>No I wasn't hit. It turned out they were drunk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>4</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>Why did you feel guilty? People really shouldn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:0_conv:0</td>\n",
       "      <td>5</td>\n",
       "      <td>I felt guilty when I was driving home one nigh...</td>\n",
       "      <td>I don't know I was new to driving and hadn't e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10968</th>\n",
       "      <td>hit:12416_conv:24832</td>\n",
       "      <td>4</td>\n",
       "      <td>I saw a huge cockroach outside my house today....</td>\n",
       "      <td>I live in Texas to so i know those feels</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10969</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>1</td>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>I have a big test on Monday, I am so nervous.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10970</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>2</td>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>What is the test on?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10971</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>3</td>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>It's for my Chemistry class. I haven't slept m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10972</th>\n",
       "      <td>hit:12423_conv:24847</td>\n",
       "      <td>4</td>\n",
       "      <td>I have a big test on Monday. I am so nervous, ...</td>\n",
       "      <td>Chemistry is quite difficult,have you studied ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10973 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    conv_id  utterance_idx  \\\n",
       "0              hit:0_conv:0              1   \n",
       "1              hit:0_conv:0              2   \n",
       "2              hit:0_conv:0              3   \n",
       "3              hit:0_conv:0              4   \n",
       "4              hit:0_conv:0              5   \n",
       "...                     ...            ...   \n",
       "10968  hit:12416_conv:24832              4   \n",
       "10969  hit:12423_conv:24847              1   \n",
       "10970  hit:12423_conv:24847              2   \n",
       "10971  hit:12423_conv:24847              3   \n",
       "10972  hit:12423_conv:24847              4   \n",
       "\n",
       "                                                  prompt  \\\n",
       "0      I felt guilty when I was driving home one nigh...   \n",
       "1      I felt guilty when I was driving home one nigh...   \n",
       "2      I felt guilty when I was driving home one nigh...   \n",
       "3      I felt guilty when I was driving home one nigh...   \n",
       "4      I felt guilty when I was driving home one nigh...   \n",
       "...                                                  ...   \n",
       "10968  I saw a huge cockroach outside my house today....   \n",
       "10969  I have a big test on Monday. I am so nervous, ...   \n",
       "10970  I have a big test on Monday. I am so nervous, ...   \n",
       "10971  I have a big test on Monday. I am so nervous, ...   \n",
       "10972  I have a big test on Monday. I am so nervous, ...   \n",
       "\n",
       "                                               utterance  \n",
       "0      Yeah about 10 years ago I had a horrifying exp...  \n",
       "1                           Did you suffer any injuries?  \n",
       "2      No I wasn't hit. It turned out they were drunk...  \n",
       "3      Why did you feel guilty? People really shouldn...  \n",
       "4      I don't know I was new to driving and hadn't e...  \n",
       "...                                                  ...  \n",
       "10968           I live in Texas to so i know those feels  \n",
       "10969      I have a big test on Monday, I am so nervous.  \n",
       "10970                               What is the test on?  \n",
       "10971  It's for my Chemistry class. I haven't slept m...  \n",
       "10972  Chemistry is quite difficult,have you studied ...  \n",
       "\n",
       "[10973 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fec38d45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sad': 0,\n",
       " 'trusting': 1,\n",
       " 'terrified': 2,\n",
       " 'caring': 3,\n",
       " 'disappointed': 4,\n",
       " 'faithful': 5,\n",
       " 'joyful': 6,\n",
       " 'jealous': 7,\n",
       " 'disgusted': 8,\n",
       " 'surprised': 9,\n",
       " 'ashamed': 10,\n",
       " 'afraid': 11,\n",
       " 'impressed': 12,\n",
       " 'sentimental': 13,\n",
       " 'devastated': 14,\n",
       " 'excited': 15,\n",
       " 'anticipating': 16,\n",
       " 'annoyed': 17,\n",
       " 'anxious': 18,\n",
       " 'furious': 19,\n",
       " 'content': 20,\n",
       " 'lonely': 21,\n",
       " 'angry': 22,\n",
       " 'confident': 23,\n",
       " 'apprehensive': 24,\n",
       " 'guilty': 25,\n",
       " 'embarrassed': 26,\n",
       " 'grateful': 27,\n",
       " 'hopeful': 28,\n",
       " 'proud': 29,\n",
       " 'prepared': 30,\n",
       " 'nostalgic': 31}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9aa3f22e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m idx2label \u001b[38;5;241m=\u001b[39m {v:k \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m label2idx\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 將測試集的 label 轉成 id，用來計算測試集上的準確度\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m test_y \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: label2idx[x])\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_y)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/generic.py:5487\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5481\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5482\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5483\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5484\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5485\u001b[0m ):\n\u001b[1;32m   5486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'label'"
     ]
    }
   ],
   "source": [
    "testset = EmotionDataset(\"test\", test, tokenizer=tokenizer)\n",
    "testloader = DataLoader(testset, batch_size=256, \n",
    "                        collate_fn=create_mini_batch)\n",
    "\n",
    "# label 與 id 互相轉換的兩個 dictionary\n",
    "label2idx = testset.label_map\n",
    "idx2label = {v:k for k, v in label2idx.items()}\n",
    "\n",
    "# 將測試集的 label 轉成 id，用來計算測試集上的準確度\n",
    "test_y = test.label.apply(lambda x: label2idx[x]).values\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea25343c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94c0728997546d8b2774dfc5c3e0df7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 請我們的模型給出它的預測！\n",
    "predictions = get_predictions(model, testloader)\n",
    "# 要和在 cpu 上的 test_y 算準確度，還要把它從 GPU 上搬回來才行\n",
    "predictions = predictions.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "01592980",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = dict(enumerate(predictions.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9042409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('output.csv', 'w', newline='') as csvfile:\n",
    "    # 定義欄位\n",
    "    fieldnames = ['', 'pred']\n",
    "\n",
    "    # 將 dictionary 寫入 CSV 檔\n",
    "    writer = csv.writer(csvfile)\n",
    "\n",
    "    # 寫入第一列的欄位名稱\n",
    "    #writer.writeheader()\n",
    "\n",
    "    # 寫入資料\n",
    "    writer.writerow(fieldnames)\n",
    "    for k, v in test_dict.items():\n",
    "        writer.writerow([k, v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16943ca0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m測試集上的準確度：\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy_score(\u001b[43mtest_y\u001b[49m, predictions))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_y' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(\"測試集上的準確度：\", accuracy_score(test_y, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
